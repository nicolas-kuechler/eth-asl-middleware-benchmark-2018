\documentclass[report.tex]{subfiles}
\begin{document}
\section{Gets and Multi-gets (90 pts)}

%For this set of experiments you will use three load generating machines, two middlewares and three memcached servers. Each memtier instance should have 2 virtual clients in total and the number of middleware worker threads is 64, or the one that provides the highest throughput in your system (whichever number of threads is smaller).

In this set of experiments the behaviour of sharded and non-sharded mode for different number of keys in get requests are evaluated using three load generating machines, two middlewares and three memcached servers.
Each \emph{memtier} instance uses 2 virtual clients and so there are 6 clients per middleware and hence 12 clients in total. 

Results from the baseline with two middlewares in section \ref{exp31} show that for 12 clients there is no difference in throughput between 8, 16, 32 and 64 worker-threads and so the configuration with 8 worker-threads is used. This result is also to be expected when considering that in a closed system there can never be more requests than clients in the system and so with 8 worker-threads there are more worker-threads than clients per middleware and so for every decoded request there will always be an idle worker available for processing and the queue is always empty. In consequence, having more worker-threads cannot improve the throughput independent of the number of keys in the request or sharded / non-sharded mode. Therefore the analysis in this section does not consider the utilization of the number of worker-threads nor the state of the queue.

Details of the configuration are listed in the table below.

For all experiments the average number of keys in the multi-GETs was recorded in order to ensure that the results between different number of keys can be compared. The recordings show that in this \emph{memtier} version, each request contains exactly the specified number of keys.

\begin{center}
	\scriptsize{
		\begin{tabular}{|l|c|}
			\hline Number of servers                & 3                       \\ 
			\hline Number of client machines        & 3                       \\ 
			\hline Instances of memtier per machine & 2                       \\ 
			\hline Threads per memtier instance     & 1                       \\
			\hline Virtual clients per thread       & 2     		           \\ 
			\hline Workload                         & ratio=1:$<$Multi-Get size$>$         \\
			\hline Multi-Get behavior               & Sharded and Non-Sharded  \\
			\hline Multi-Get size                   & [1, 3, 6, 9]            \\
			\hline Number of middlewares            & 2                       \\
			\hline Worker threads per middleware    & 8 \\
			\hline Repetitions                      & 3 or more (at least 1 minute each)               \\ 
			\hline 
		\end{tabular}
	} 
\end{center}

In this setting the focus lies on GET and multi-GET requests because the performance of SET requests was already extensively analysed in section \ref{exp4} in the same setting with 3 clients, 2 middlewares and 3 servers.

However in order to apply the interactive law to validate the throughput and response time measurements for the read workload, the average SET response time as measured on the client is used as client thinking time. This reflects the fact that memtier alternately generates a GET/multi-GET and a SET request. So in the viewpoint of the middleware, the client waits the round trip time and the SET response time before sending the next GET/multi-GET request. As table \todo{add interactive law table} shows, the interactive law holds for all measurements in this section.

%For multi-GET workloads, memtier will generate a mixture of SETs, GETs, and multi-GETs. Memtier only allows to specify the maximum number of keys in a multi-GET request. Therefore, be aware that requests can also contain fewer keys than the provided value. It is recommended to record the average size of the multi-GETs. You will have to measure response time on the client as a function of multi-get size, with and without sharding on the middlewares.
\todo{compare response time decomposition between sharded and non-sharded -> would expect sharded has longer wtt but shorter sst}

\subsection{Sharded Case}

%Run multi-gets with 1, 3, 6 and 9 keys (memtier configuration) with sharding enabled (multi-gets are broken up into smaller multi-gets and spread across servers). Plot average response time as measured on the client, as well as the 25th, 50th, 75th, 90th and 99th percentiles.
This section evaluates the sharded mode for multi-GETs with 1, 3, 6 and 9 keys.


\begin{figure}
	\begin{subfigure}[b]{.49\linewidth}
		\centering
		\includegraphics[width=\linewidth]{data/exp51_s_rt_mget_perc_client.pdf}
		\caption{sharded}\label{exp51_s_rt_mget_perc}
	\end{subfigure}\hfill
	\begin{subfigure}[b]{.49\linewidth}
		\centering
		\includegraphics[width=\linewidth]{data/exp52_ns_rt_mget_perc_client.pdf}
		\caption{non-sharded}\label{exp52_ns_rt_mget_perc}
	\end{subfigure}%
	\caption{Average response time and 25th, 50th, 75th, 90th and 99th percentiles of different multi-get sizes. The error metric is the sample standard deviation over repetitions.}\label{exp5_rt_mget_perc}
\end{figure}

\begin{figure}
	\begin{subfigure}[b]{.49\linewidth}
		\centering
		\includegraphics[width=\linewidth]{data/exp51exp52_tp_mget.pdf}
		\caption{Throughput with bandwidth limit get}\label{exp5_tp}
	\end{subfigure}\hfill
	\begin{subfigure}[b]{.49\linewidth}
		\centering
		\includegraphics[width=\linewidth]{data/exp51_s_rt_comp.pdf}
		\caption{Response Time Decomposition Sharded}\label{exp51_s_rt_comp}
	\end{subfigure}%
	\caption{Throughput and response time decomposition}
\end{figure}


\begin{figure}
	\begin{subfigure}[b]{.49\linewidth}
		\centering
		\includegraphics[width=\linewidth]{data/exp51_s_get_sst.pdf}
		\caption{sharded}\label{exp51_s_get_sst}
	\end{subfigure}\hfill
	\begin{subfigure}[b]{.49\linewidth}
		\centering
		\includegraphics[width=\linewidth]{data/exp52_ns_get_sst.pdf}
		\caption{non-sharded}\label{exp52_s_get_sst}
	\end{subfigure}%
	\caption{Server Service Time}
\end{figure}


\subsubsection{Explanation}

Figure \ref{exp5_tp} shows that multi-GETs with more than 3 keys are limited by the network upload bandwidth of the server VM. The three server have a combined upload bandwidth of 297.8 MBit/sec as measured with \emph{iperf}. Since every 4096B value has to be transported from a server VM to a middleware VM independent of sharded or non-sharded mode, a request with 6 keys requires the transportation of at least 24576 bytes without considering any additional overhead. This limits the throughput to 1514 ops/sec which is reached in both the sharded and non-sharded case and thus heavily influences the analysis.

The network bottleneck becomes also evident when considering the percentiles and the average of the response time in figure \ref{exp51_s_rt_mget_perc}. The 75th, 90th and 99th percentile and the average response time have a clear knee between multi-GET requests with 3 and 6 values. Then for multi-GETs with 9 values the knee is also visible in the 50th percentile. Only the 25th percentile remains stable, which means that at least 25\% of the multi-GET requests are basically not affected by the bottleneck for multi-GET requests with 9 or less values.

In sharded mode it could be expected that there is a trade-off between additional worker-thread processing time disassembling and assembling the multi-GET request and a shorter server service time due to the smaller number of values that need to be handled by a single \emph{memcached} server. However as figure \ref{exp51_s_rt_comp} shows the worker-thread processing time is a negligible factor in the implementation of the middleware in sharded mode. It is the server service time that dominates the response time. Here a problem of the sharded mode arises, a worker-thread needs to wait for the response of all involved \emph{memcached} servers and thus the slowest server determines the total server service time of the request.  The effect is clearly visible in figure \ref{exp51_s_get_sst} where server 3 is considerably slower in particular for requests with more keys and hence the total server service time is also long. The average total server service time is even worse than the average server service time of server 3 because for some requests server 3 may be faster than server 1 or 2 but the then the limiting factor is server 1 or 2. Effectively the slowest responding server is the bottleneck of the system and the problem is aggravated by the network bottleneck for multi-GETs with more than 3 values.

The same phenomena was previously observed in section \ref{exp4} for a write-only workload with 3 server VMs.\footnote{Since the VMs were restarted for experiments in this section, another server is the slowest.}

%Provide a detailed analysis of the results (e.g., bottleneck analysis, component utilizations, average queue lengths, system saturation). Add any additional figures and experiments that help you illustrate your point and support your claims.

\subsection{Non-sharded Case}

This section evaluates the non-sharded mode for multi-GETs with 1, 3, 6 and 9 keys.
%Run multi-gets with 1, 3, 6 and 9 keys (memtier configuration) with sharding disabled. Plot average response time as measured on the client, as well as the 25th, 50th, 75th, 90th and 99th percentiles.

%\begin{center}
%	\scriptsize{
%		\begin{tabular}{|l|c|}
%			\hline Number of servers                & 3                       \\ 
%			\hline Number of client machines        & 3                       \\ 
%			\hline Instances of memtier per machine & 2                       \\ 
%			\hline Threads per memtier instance     & 1                       \\
%			\hline Virtual clients per thread       & 2                		 \\ 
%			\hline Workload                         & ratio=1:$<$Multi-Get size$>$              \\
%			\hline Multi-Get behavior               & Non-Sharded             \\
%			\hline Multi-Get size                   & [1, 3, 6, 9]                  \\
%			\hline Number of middlewares            & 2                       \\
%			\hline Worker threads per middleware    & 8 \\
%			\hline Repetitions                      & 3 or more (at least 1 minute each) \\ 
%			\hline 
%		\end{tabular}
%	} 
%\end{center}


\subsubsection{Explanation}

%Provide a detailed analysis of the results (e.g., bottleneck analysis, component utilizations, average queue lengths, system saturation). Add any additional figures and experiments that help you illustrate your point and support your claims.
The network bottleneck identified in the sharded mode also directly applies to the non-sharded mode and so results for multi-GETs with more than 3 keys have to take this into consideration.
 
The network bottleneck also directly influences the response time as seen in figure \ref{exp52_ns_rt_mget_perc}, because for the average, the 90th and 99th percentile there is a knee between 3 and 6 keys in a multi-GET request. The 75th percentile has the knee at 6 keys per request and the 25th and 50th percentile remain stable up to 9 keys. This shows that at least 50\% requests are almost not affected by the network bottleneck which is more than in sharded mode. The fact that less requests are affected in non-sharded mode by the bottleneck can be explained by a simple probability model.

Assuming each message from the server to the middleware is delayed with probability of 0.5, in the non-sharded mode each request receives only one message from a server and so the probability of not being delayed is 0.5. In sharded mode each request receives 3 messages from a server and so the probability of at least one of those being delayed is $(1-0.5^3)=0.875$ which results in the whole request being delayed.

Despite the fact that in non-sharded mode less requests are delayed, figure \ref{exp52_ns_rt_mget_perc} also shows that if a request is affected by the bottleneck in non-sharded mode, the effect on response time can be much more drastic. This can be seen by the percentile rank of the 99th percentile for multi-GETs with 6 and 9 keys. Additional support for this claim comes from the less stable server service time (Fig. \ref{exp52_s_get_sst}).

Further it can be observed that the average total server service time in non-sharded mode is less affected by the slowest server because the round robin scheme takes care of the fact that only every third request is sent to this server. This shows the potential of a more sophisticated load balancing scheme considering the current throughput obtained by each server VM.



\subsection{Histogram}

%For the case with 6 keys inside the multi-get, display four histograms representing the sharded and non-sharded response time distribution, both as measured on the client, and inside the middleware. Choose the bucket size in the same way for all four, and such that there are at least 10 buckets on each of the graphs.
The bucket size of 0.21 was selected by applying the \emph{Freedmanâ€“Diaconis rule} (bucket size $ = 2 \frac{IQR(x)}{\sqrt[3]{n}}$ where $IQR(x)$ is the interquartile range) on the middleware response time measurements of the sharded case and then kept constant for all 4 cases. All outliers taking more than 15 ms are added to the bin at 15 ms. Each bucket contains an error bar indicating the standard deviation of the frequency per bin over the repetitions.

The histogram with the middleware measurements does not filter out warmup and cooldown phase to allow a fair comparison between client and middleware. 

As previously explained the response time measured on the client is larger than on the middleware by approximately 1 millisecond resulting in a shift of the time distribution in the histogram.

Consistent with the results from the previous section the data in figure \ref{exp5_hist} indicates that the non-sharded case has a longer tail in the response time distribution than the sharded case but at the same time generally also more requests have a small response time than in the sharded case.

Artifac

\begin{figure}
	\begin{subfigure}[b]{.49\linewidth}
		\centering
		\includegraphics[width=\linewidth]{data/exp51_s_mget6_hist_mw.pdf}
		\caption{Sharded - Middleware}
	\end{subfigure}\hfill
	\begin{subfigure}[b]{.49\linewidth}
		\centering
		\includegraphics[width=\linewidth]{data/exp51_s_mget6_hist_client.pdf}
		\caption{Sharded - Client}
	\end{subfigure} \\
	\begin{subfigure}[b]{.49\linewidth}
		\centering
		\includegraphics[width=\linewidth]{data/exp52_ns_mget6_hist_mw.pdf}
		\caption{Non-Sharded - Middleware}
	\end{subfigure}\hfill
	\begin{subfigure}[b]{.49\linewidth}
		\centering
		\includegraphics[width=\linewidth]{data/exp52_ns_mget6_hist_client.pdf}
		\caption{Non-Sharded - Client}
	\end{subfigure}%
	\caption{Sharded and non-sharded response time distribution for multi-gets with 6 keys as measured inside the middleware and on the client}\label{exp5_hist}
\end{figure}

\subsection{Summary}

%Provide a detailed comparison of the sharded and non-shareded modes. For which multi-GET size is sharding the preferred option? Provide a detailed analysis of your system. Add any additional figures and experiments that help you illustrate your point and support your claims.

Due to the network bottleneck a fair comparison between sharded and non-sharded is difficult. 
However with 3 keys per multi-GET request the collected data suggests that using the non-sharded mode is better because the gain in server service time as a consequence of only having one instead of three values to fetch is outweighed by the waiting time for the answer of the slowest server. For 6 and 9 keys per multi-GET request there is a trade-of in presence of the network bottleneck. On average the response time in non-sharded mode is smaller than in sharded mode because as explained in the previous section less requests are affected by the network bottleneck. However using the non-sharded mode the tail in the response time distribution is longer and so the 99th percentile rank is significantly higher than in the sharded mode. This results in large response times for some requests.

So for multi-GETs with 6 and 9 keys, the preferred option in presence of the network bottleneck depends on whether the application requires to be good on average or not terrible in the worst case. 
\todo{how can it be that for 6 and 9 the avg response time is smaller in non-sharded but the throughput is the same?} 

\todo{need to add more to satisfy these points}
Summary is consistent with previous experiments 5 Summary identifies trends and important parameters for performance 5 Summary relates performance for different request sizes 5 Summary related the sharded and non-sharded modes 5 Summary relates the response time on the clients and middleware (e.g. histograms)

\end{document}