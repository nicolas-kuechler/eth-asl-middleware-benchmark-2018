\documentclass[report.tex]{subfiles}
\begin{document}
\section{Queuing Model (90 pts)}

%Note that for queuing models it is enough to use the experimental results from the previous sections. It is, however, possible that the numbers you need are not only the ones in the figures we asked for, but also the internal measurements that you have obtained through instrumentation of your middleware.
All results in this section were obtained using the software \cite{queueing}.
In Section \ref{exp4} it was shown that the interactive law holds for all measurements and so the check is omitted here.


\begin{table}
	\centering
	\begin{tabular}{r|lcccccccc|}
		\multicolumn{3}{c}{}  & \multicolumn{7}{c}{Number of Clients}\Tstrut \\ 
		\multicolumn{3}{c}{}   & 6 & 12 & 24 & 48 & 72 & 96 & \multicolumn{1}{c}{144} \\ 
		\cline{2-10}
		\multirow{2}{*}{8 WT } & $\mu_{M/M/1} = 6385$ & $\lambda = $ & 2357 & 4520 & 5562 & 6262 & 6244 & 6173 & 6320\Tstrut \\
		& $\mu_{M/M/16} = 399$ & $\rho =$ & 0.37 & 0.71 & 0.87 & 0.98 & 0.98 & 0.97 & 0.99 \\
		\cline{2-10}
		\multirow{2}{*}{16 WT } & $\mu_{M/M/1} = 8313$ & $\lambda = $ & 2367 & 4335 & 5699 & 7664 & 8103 & 8201 & 8266\Tstrut \\
		& $\mu_{M/M/32} = 260$ & $\rho =$ & 0.28 & 0.52 & 0.69 & 0.92 & 0.97 & 0.99 & 0.99 \\
		\cline{2-10}
		\multirow{2}{*}{32 WT } & $\mu_{M/M/1} = 10504$ & $\lambda = $ & 2397 & 4456 & 5708 & 7975 & 9267 & 10155 & 10420\Tstrut \\
		& $\mu_{M/M/64} = 164$ & $\rho =$ & 0.23 & 0.42 & 0.54 & 0.76 & 0.88 & 0.97 & 0.99 \\
		\cline{2-10}
		\multirow{2}{*}{64 WT } & $\mu_{M/M/1} = 11848$ & $\lambda = $ & 2405 & 4312 & 5738 & 8027 & 9339 & 10300 & 11210\Tstrut \\
		& $\mu_{M/M/128} = 93$ & $\rho =$ & 0.2 & 0.36 & 0.48 & 0.68 & 0.79 & 0.87 & 0.95 \\
		\cline{2-10}
	\end{tabular}
	\caption{Arrival rates $\lambda$, service rate $\mu$ and traffic intensity $\rho$ for both M/M/1 and M/M/m models for different number of worker-threads} \label{exp70_arrival_service_traffic} 
\end{table}


\begin{figure}
	\begin{subfigure}[b]{.33\linewidth}
		\centering
		\includegraphics[width=\linewidth]{data/exp70_rt_w8.pdf}
	\end{subfigure}\hfill
	\begin{subfigure}[b]{.33\linewidth}
		\centering
		\includegraphics[width=\linewidth]{data/exp70_queue_w8.pdf}
	\end{subfigure}\hfill
	\begin{subfigure}[b]{.33\linewidth}
		\centering
		\includegraphics[width=\linewidth]{data/exp70_qwt_w8.pdf}
	\end{subfigure}
	\caption{Response time, number of requests in queue and waiting time in queue as a function of number of clients as measured in simulation and calculated using an M/M/1 and M/M/m model for the configuration with 8 worker-threads.}\label{exp70_w8}
\end{figure}

\begin{figure}
	\begin{subfigure}[b]{.33\linewidth}
		\centering
		\includegraphics[width=\linewidth]{data/exp70_rt_w16.pdf}
	\end{subfigure}\hfill
	\begin{subfigure}[b]{.33\linewidth}
		\centering
		\includegraphics[width=\linewidth]{data/exp70_queue_w16.pdf}
	\end{subfigure}\hfill
	\begin{subfigure}[b]{.33\linewidth}
		\centering
		\includegraphics[width=\linewidth]{data/exp70_qwt_w16.pdf}
	\end{subfigure}
	\caption{Response time, number of requests in queue and waiting time as a function of number of clients in queue as measured in simulation and calculated using an M/M/1 and M/M/m model for the configuration with 16 worker-threads.}\label{exp70_w16}
\end{figure}

\begin{figure}
	\begin{subfigure}[b]{.33\linewidth}
		\centering
		\includegraphics[width=\linewidth]{data/exp70_rt_w32.pdf}
	\end{subfigure}\hfill
	\begin{subfigure}[b]{.33\linewidth}
		\centering
		\includegraphics[width=\linewidth]{data/exp70_queue_w32.pdf}
	\end{subfigure}\hfill
	\begin{subfigure}[b]{.33\linewidth}
		\centering
		\includegraphics[width=\linewidth]{data/exp70_qwt_w32.pdf}
	\end{subfigure}
	\caption{Response time, number of requests in queue and waiting time as a function of number of clients in queue as measured in simulation and calculated using an M/M/1 and M/M/m model for the configuration with 32 worker-threads.}\label{exp70_w32}
\end{figure}

\begin{figure}
	\begin{subfigure}[b]{.33\linewidth}
		\centering
		\includegraphics[width=\linewidth]{data/exp70_rt_w64.pdf}
	\end{subfigure}\hfill
	\begin{subfigure}[b]{.33\linewidth}
		\centering
		\includegraphics[width=\linewidth]{data/exp70_queue_w64.pdf}
	\end{subfigure}\hfill
	\begin{subfigure}[b]{.33\linewidth}
		\centering
		\includegraphics[width=\linewidth]{data/exp70_qwt_w64.pdf}
	\end{subfigure}
	\caption{Response time, number of requests in queue and waiting time as a function of number of clients in queue as measured in simulation and calculated using an M/M/1 and M/M/m model for the configuration with 8 worker-threads.}\label{exp70_w64}
\end{figure}

\subsection{M/M/1}

%Build queuing model based on Section 4 (write-only throughput) for each worker-thread configuration of the middleware. Use one M/M/1 queue to model your entire system. Motivate your choice of input parameters to the model. Explain for which experiments the predictions of the model match and for which they do not.

In this section the entire system from Section \ref{exp4} (write-only throughput) is modelled using one M/M/1 queue. An M/M/1 queue assumes that the interarrival times and service times of requests are exponentially distributed and that requests are waiting in a possibly unbounded FCFS queue\footnote{first come first served queue} for processing by the only server in the system.

A M/M/1 queue is completely defined by two parameters, the arrival rate $\lambda$ and the service rate $\mu$.
The average number of requests per second arriving in the system depends on the user load and is measured in the net-thread of each middleware. This measurement is then used as the arrival rate $\lambda$ for the M/M/1 queue.
The service rate $\mu$ is independent of the user load and characterizes how fast the system is able to serve requests in a certain configuration. \todo{verify this formulation} 
The maximum observed throughput of the system with a certain configuration can be used as an estimate for the service rate because this shows that the system is capable of serving requests this fast. 
The service rate $\mu$ is defined as the maximum throughput observed for a worker-thread configuration independent of the number of clients.

The chosen parameters are listed in table \ref{exp70_arrival_service_traffic}.
The system is always stable because the traffic intensity  $\rho= \frac{\lambda}{\mu}$ is always smaller than 1.
The traffic intensity also represents the utilization of the system and this matches nicely with the results from section \ref{exp4}, where it was shown that the system saturates when there are considerably more clients than total worker-threads in the system. \footnote{recall that there are two middlewares in the system and hence the total number of worker-threads is two times the number of worker-threads per middleware which are listed in table \ref{exp70_arrival_service_traffic})}
Apart from the traffic intensity the performance of the model is evaluated by comparing it to the measured response time, number of requests in the request queue and waiting time in the request queue.

The M/M/1 model constantly underestimates the response time because it assumes there is only a single server (worker-thread) and so the given service rate implies that this single server processes each job rapidly and hence the predicted response time is much lower than the observed response time. In the actual implementation of the middleware the individual service time of a worker-thread is much larger and the achieved throughput is only possible because multiple worker-threads process requests in parallel.
In configurations with relatively few worker-threads (Fig. \ref{exp70_w8}, \ref{exp70_w16}) the discrepancies in response time are smaller compared to configurations with more working-threads (Fig. \ref{exp70_w32}, \ref{exp70_w64}) because the concurrency in the system, which the M/M/1 model fails to capture, increases in the number of worker-threads.
Both the number of requests in the queue and the waiting time in the queue are approximated well with the M/M/1 model because there the assumption of a single FCFS queue matches well with the request queue in the middleware. This accuracy is only possible because the decoding in the net-thread is not a bottleneck where requests are queued for a long time. 

\subsection{M/M/m}

%Build an M/M/m model based on Section 4, where each middleware worker thread is represented as one service.  Motivate your choice of input parameters to the model. Explain for which experiments the predictions of the model match and for which they do not.

In this section the entire system from Section \ref{exp4} (write-only throughput) is modelled using one M/M/m queue. An M/M/m queue assumes that the interarrival times and service times of requests are exponentially distributed and that requests are waiting in a possibly unbounded FCFS queue\footnote{first come first served queue} for processing by one of the $m$ servers in the system.

An M/M/m queue is completely defined by three parameters, the arrival rate $\lambda$, the service rate $\mu$ and the number of servers $m$.
The arrival rate $\lambda$ and the service rate $\mu$ are defined as in the M/M/1 model with the only difference that the service rate is divided by the number of servers $m$ in the system because when assuming that there are $m$ servers that split the workload equally, then each server is responsible for $\frac{1}{m}$ of the total number of serviced requests. The parameter $m$ is chosen such that it matches the total number of worker-threads in the system which is two times the number of worker-threads per middleware since there are two middlewares.

It can be expected that the M/M/m queue is a much better model for the response time than the M/M/1 queue because it accounts for the concurrency of the worker-threads. The predictions for the number of requests in the queue and queue waiting time should be relatively similar to the M/M/1 model. The traffic intensity for the M/M/m model is identical to the traffic intensity in the M/M/1 by construction and as seen in the previous section it nicely captures the utilization of the system.

While the system is under-saturated when there are more worker-threads than clients, the M/M/m model is a bad model for the response time. This becomes in particularly evident in figure \ref{exp70_w64} with 128 worker-threads in total but the same is also visible with less worker-threads. The reason for this phenomena is that \todo{add explanation}.
Despite the fact that in the under-saturated phase the M/M/m model fails to capture the response time accurately, when the system is running at near to optimal load with approximately equal number of worker-threads in total and clients, then the M/M/m model is a good model for the response time and outperforms the M/M/1 model significantly.
When there are much more clients per middleware than worker-threads, the accuracy of the model decreases and there can even be some artefacts as observed in figure  \ref{exp70_w8}.

As expected the difference between the predictions for number of requests waiting in queue and waiting time are equally good to the M/M/1 model because the model accurately models the situation in the middleware with a single FCFS request queue where all requests are waiting for service. Additionally it has to be noted that this accuracy is only possible because the net-thread is not the bottleneck of the system because otherwise requests would already be queued there which would not be reflected by the number of requests waiting in the request queue and the waiting time in this queue.


\subsection{Network of Queues}

%Based on Section 3, build a network of queues which simulates your system. Motivate the design of your network of queues and relate it wherever possible to a component of your system. Motivate your choice of input parameters for the different queues inside the network. Perform a detailed analysis of the utilization of each component and clearly state what the bottleneck of your system is. Explain for which experiments the predictions of the model match and for which they do not.

The results were obtained using the convolution algorithm for general load-dependent service centers as implemented in \cite{queueing}.
Details of the algorithm and further references can be found in the documentation of the \emph{queueing} software.


\paragraph{One Middleware - Model}

The net-thread is modelled as an M/M/1 queue using the measured decoding time as the service time.
This is a sensible choice because as shown in previous sections, the decoding time of the net-thread is independent of the number of clients and all requests have to go through this decoding stage which explains the visit ratio of 1.

The request queue in combination with the $m$ worker-threads is modelled as an M/M/m queue with a visit ratio of 1 because with a single middleware all requests pass through there. Due to the architecture of the middleware, the \emph{memcached} server is not modelled as a separate queue because a worker-thread cannot process a new request until the \emph{memcached} server responded and so the time for request to the \emph{memcached} server is part of the worker-thread service time. This modelling choice leads to a conflict in the service time of a worker-thread because as shown in previous sections the server service time of the \emph{memcached} server is depending on the number of busy worker-threads and so in an under-saturated system the worker-thread service time is smaller than in a system where all worker-threads are busy. 
It was decided to use the measured worker-thread processing time when all worker-threads are busy as the service time for a server in the M/M/m queue. In consequence the model predictions for the throughput are only accurate when there are more clients than worker-threads because as seen in previous sections the worker-thread processing time is independent of the user-load from the point where there are more users than worker-threads.

The network between client VM and middleware VM and vice versa are modelled as two separate delay centers each with a service time of half the measured round trip time. In between there is a client delay center with 0 service time which has no influence on the model but fits well with the conceptual model of the system. All three delay centers have a visit ratio of 1 because all requests pass through them.

Figure \ref{exp70_noq_1mw} shows the detailed structure of the network of queues with the respective parameters.

\paragraph{One Middleware - Model Performance}
The network of queues model with a single middleware was applied to both the read-only and write-only workload from section \ref{exp31}.
In order to evaluate the performance of the model, the predicted and measured throughput are compared for different number of clients.
In addition the utilization of each component as predicted by the model is listed in order to identify the bottleneck component.


For the write-only workload the configuration with 64 worker-threads is used because as shown it leads to the highest throughput.
Figure \ref{exp70_noq_wo} shows that for the reasons described above, the model fails to predict the throughput when there are less clients than worker-threads but afterwards the model is accurate. The component utilizations in figure \ref{exp70_noq_wo} show that worker-threads become the bottleneck if there are considerably more clients than worker-threads. This is consistent with the results from section \ref{exp31}.

For the read-only workload the configuration with 8 worker-threads is used because as shown there is no point in using more worker-threads because the server VM upload bandwidth limit is already reached with 8 worker-threads. The prediction for the throughput is accurate as soon as the user load is such that all 8 worker-threads are kept constantly busy (Fig. \ref{exp70_noq_ro}). This is due to the choice of worker-thread service time as described above . The component utilizations in figure \ref{exp70_noq_ro} show that the worker-threads are the bottleneck in the model. This is only partially true because as seen in section \ref{exp31} the real bottleneck is the upload bandwidth capacity of the server VM. However, since the limited upload bandwidth capacity between server VM and middleware VM is not explicitly modelled, the model also does not have the power to detect this and instead the limit manifests itself in the worker-thread processing time.

\begin{figure}
	\begin{minipage}[c]{0.45\linewidth}
		\centering
		\scriptsize{
			\begin{tabular}{|l|c|c|l|}
				\hline 
				& $V$ & $S$ & Type \Tstrut\\ 
				\hline 
				Client & 1 & 0.0  & delay center \Tstrut\\ 
				\hline 
				Network Client - MW & 1 &  & delay center \Tstrut\\  
				Net-Thread & 1 &  & M/M/1 \\ 
				Worker-Threads & 1 &  & M/M/m  \\ 
				Network MW - Client & 1 &  & delay center \\ 
				\hline 
			\end{tabular} 
		} 
	\end{minipage}
	\hspace{0.5cm}
	\begin{minipage}[c]{0.45\linewidth}
	\centering
	\includegraphics[width=\textwidth]{data/noq_1mw.png}
\end{minipage}
	\caption{Network of Queue with one middleware}
	\label{exp70_noq_1mw}
\end{figure}


\paragraph{Two Middlewares - Model}

The network of queues model for the system in section \ref{exp32} with two middlewares is similar to the network of queues with one middleware.
The difference is that all components apart from the client delay center are duplicated and in consequence each of them has a visit ratio of 0.5.
This is a reasonable choice because half of the clients use middleware 1 and the other half uses middleware 2. As shown in section \ref{exp32} the \emph{memcached} service time remains constant when the user load is such that all worker-threads in the system are kept constantly busy and so the dependence between the two middlewares can be neglected. The motivation for the choice of the component service times from the model involving one middleware also directly apply to this model with two middlewares.

The details of the model are listed in figure \ref{exp70_noq_2mw}.

\paragraph{Two Middlewares - Model Performance}
The network of queues model with a two middlewares was applied to both the read-only and write-only workload from section \ref{exp32}.
As in the model with a single middleware, the predicted and measured throughput are compared for different number of clients.
And the utilization of each component as predicted by the model is listed in order to identify the bottleneck component. For the write-only workload the configuration with 64 worker-threads per middleware is used and for the read-only workload the configuration with 8 worker-threads per middleware is used because they lead to the maximal throughput.

In the write-only workload, the model is able to predict the throughput accurately when all 128 worker-threads are busy which happens only for more than 128 clients. This is due to the familiar issue with the worker-thread service time that up to then would depend on the user load in the real system but is kept fixed in the model.
The component utilizations in figure \ref{exp70_noq_wo} show that the bottleneck is once again the worker-threads which matches the analysis of section \ref{exp32}. \todo{does it? could also be server that is saturating} Compared to the system with one middleware, the point of saturation is reached for a larger number of clients which manifests itself both in the component utilizations and the throughput.

In the read-only workload the situation is the same as in the model with one middleware. The throughput predictions match when the number of clients is such that all 16 workers are constantly busy. The bottleneck is identified as the worker-threads which is correct in the sense that the bandwidth bottleneck of the server VM, which was identified as the actual bottleneck in section \ref{exp32}, is part of this component.
However, in the read-only workload the granularity of the network model does not allow to detect the bandwidth limit of the server VM as the real problem. 

\begin{figure}
	\begin{minipage}[c]{0.45\linewidth}
		\centering
		\scriptsize{
			\begin{tabular}{|l|c|c|l|}
				\hline 
				& $V$ & $S$ & Type \Tstrut\\ 
				\hline 
				Client & 1 & 0.0  & delay center \Tstrut\\ 
				\hline 
				Network Client - MW 1 & 0.5 &  & delay center \Tstrut\\ 
				Net-Thread MW 1 & 0.5 &  & M/M/1 \\ 
				Worker-Threads MW 1 & 0.5 &  & M/M/m  \\ 
				Network MW 1 - Client & 0.5 &  & delay center \\ 
				\hline 
				Network Client - MW 2 & 0.5 &  & delay center \Tstrut\\  
				Net-Thread MW 2 & 0.5 &  & M/M/1 \\ 
				Worker-Threads MW 2 & 0.5 &  & M/M/m  \\
				Network MW 2 - Client & 0.5 &  & delay center \\ 
				\hline 
			\end{tabular} 
		} 
	\end{minipage}
	\hspace{0.5cm}
	\begin{minipage}[c]{0.45\linewidth}
		\centering
		\includegraphics[width=\textwidth]{data/noq_2mw.png}
	\end{minipage}
	\caption{Network of Queue with two middlewares}
	\label{exp70_noq_2mw}
\end{figure}


\begin{figure}
	\begin{subfigure}[b]{.49\linewidth}
		\centering
		\includegraphics[width=\linewidth]{data/exp70_noq_tp_wo.pdf}
	\end{subfigure}\hfill
	\begin{subfigure}[b]{.49\linewidth}
		\centering
		\includegraphics[width=\linewidth]{data/exp70_noq_util_wo.pdf}
	\end{subfigure}%
	\caption{Write-Only}\label{exp70_noq_wo}
\end{figure}

\begin{figure}
	\begin{subfigure}[b]{.49\linewidth}
		\centering
		\includegraphics[width=\linewidth]{data/exp70_noq_tp_ro.pdf}
	\end{subfigure}\hfill
	\begin{subfigure}[b]{.49\linewidth}
		\centering
		\includegraphics[width=\linewidth]{data/exp70_noq_util_ro.pdf}
	\end{subfigure}%
	\caption{Read-Only}\label{exp70_noq_ro}
\end{figure}

\todo{do figures properly and noq for 2 mws needs to be smaller}


\end{document}