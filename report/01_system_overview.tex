\documentclass[report.tex]{subfiles}
\begin{document}
\section{System Overview (75 pts)}

The column width is: \the\columnwidth
need to remove this
\todo{check 20-35 pages}
%Describe the implementation of your system and highlight design decisions relevant for the experiments. Explain how messages are parsed and how statistics are gathered in a multi-threaded setting. Provide figures containing all the threads and queues in your system (including the network and the memcached servers). Include illustrations that show how requests of different types are handled (e.g., components involved in processing the request and method calls). Please include all details necessary to understand artifacts and effects in your experiments that arise from your implementation choices. \todo{remove}


The system is a middleware platform for the popular main-memory key-value store \emph{memcached}. \todo{cite memcached.org}
It enables to balance the read workload between up to three memcached instances possibly located on different servers by replicating all writes to all memcached instances.


\subsection{Middleware Architecture}
\subsubsection{High-Level Overview}

\begin{figure}
	\centering
	\includegraphics[width=\linewidth]{data/system-overview.png}
	\caption{System Overview}
\end{figure}
\todo{do properly with pdf and number components to reference them}
The middleware system is composed of three main components. 
A net-thread which uses a Java Nio Selector to handle multiple socket channels to clients listens on a tcp port for client requests. and decodes the incoming requests and puts them into a queue.

A request queue (\emph{LinkedBlockingQueue.java}) that buffers decoded requests while they are waiting for a worker-thread to process them.

Multiple worker-threads that take requests from the queue and process them according to their type.

\paragraph{Start}
Use command line  arguments to configure the middleware.
On start up of the middleware a configured number of worker-threads and a single net-thread are started.
Each worker-thread builds a tcp connection to each memcached server which is kept open during the run of the middleware.

\paragraph{Run}
The net-thread \emph{(NetThread.java)} listens on a configured tcp port for client requests. The different client channels are handled using a Selector.
After decoding the incoming request in the net-thread (see \ref{request-decoding}) they are put into a queue.

The worker-threads \emph{(WorkerThread.java)} take requests from the queue and process them according to their their type. (see \ref{request-processing}). Then they send back the response to the client via the channel.


\paragraph{Shutdown}
To stop the middleware a shutdown hook was registered that listens for a linux kill command.
Interrupt the net-thread and all worker-threads and ensures all logs have been written to the respective log file.

\subsubsection{Request}
The middleware supports set, get and multi-get requests.

Logically each request from a client is represented using an instance of \emph{SetRequest.java}, \emph{GetRequest.java} or \emph{MultiGetRequest.java}. They all inherit basic functionality from \emph{AbstractRequest.java}.
These request objects are created in the net-thread by the decoder (see \ref{request-decoding}) and put into a \emph{BlockingQueue} where they wait to be processed by a worker-thread (see \ref{request-processing}).

Apart from containing the request command, they also serve as a container for the tcp socket channel to the client and for timestamps collected at different points in the system (see \ref{measured-points}).

In addition they also contain information about their assigned memcached server id.

\subsubsection{Request Decoding}\label{request-decoding}
In the net-thread the incoming requests are decoded one by one using the function \emph{decode(ByteBuffer buffer)} of the request decoder \emph{(RequestDecoder.java)}.
Since every request needs to pass this function the decoding is done on byte level to avoid unnecessary overhead.
Apart from checking that the client request is supported by the middleware the decoder also verifies that the request is completely read. In case the decoder encounters an unsupported operation or a malformed request \emph{(UnknownRequest.java)}, the request is discarded until a newline character is read. Then an error is returned to the client and a log entry is created. If a request is not complete yet, the decoder signals the net-thread that more is expected and the net-thread will append the next content arriving from the client channel to the same buffer to complete the request.

In the following the decoding of the three different request types is explained. \todo{maybe add decoding state machine}

\paragraph{SET} \texttt{set <key> <flags> <exptime> <bytes>[noreply]\textbackslash r\textbackslash n<datablock>\textbackslash r\textbackslash n} 

After reading the set in the beginning of the command, the decoder skips over key, flags and expiration time before reading the bytes field to determine if the data block is complete. If the request is complete, a \emph{SetRequest.java} is created.

\paragraph{GET / MULTI-GET} \texttt{get <key>\textbackslash r\textbackslash n} or \texttt{get <key1> <key2> ... <key10>\textbackslash r\textbackslash n}

After reading the get in the beginning of the command, the decoder determines the number of keys and checks that the request is complete. If there is only a single key, then a \emph{GetRequest.java} is created. Otherwise a \emph{MultiGetRequest.java} is created.

For get and multi-get requests the decoder assigns each request a server (or for sharded mutli-get multiple servers) in a round-robin scheme. (see more on workload balancing in \ref{workload-balancing})


\subsubsection{Request Processing}\label{request-processing}

A worker-thread takes a request from the queue and processes it depending on the request type.

\emph{ServerMessage.java} by calling the \emph{getServerMessages()} function of the request object.

The worker-thread sends these messages one after the other to the specified servers.
The different channels to the servers are monitored using a Selector. Whenever a response of a server arrives it 
is given to the request using the function \emph{putServerResponse(serverId, buffer)}. The request assembles all responses and when all arrived a response is written back to the client through the socket channel.

\paragraph{Set} The request command is sent to all servers. If all servers answer with \texttt{STORED\textbackslash r\textbackslash n} then \texttt{STORED\textbackslash r\textbackslash n} is sent to the client. 

If at least one server answers with an error message, then the error message which arrived last is relayed to the client.

\paragraph{Get} The request command is sent to the server specified by the round-robin scheme in the net-thread.
The response of the server is directly relayed to the client.

\paragraph{MultiGet} The processing is different depending on the sharded/non-sharded mode. In case of non-sharded mode, the processing is identical to a get request where the message is sent to one server and the response is directly relayed to the client. In case of sharded mode, the request is split into up to three smaller requests\todo{explain splitting rule} . Each of them is sent to the server determined by the round-robin scheme. Then each server response is fed back to the request that is responsible for reordering the results. When all responses arrived, the reordered response is sent to the client.

\subsubsection{Workload Balancing}\label{workload-balancing}
The round robin scheme applied for get and multi-get requests allows to balance the read-workload among multiple servers.

As described in \ref{request-decoding} each get and multi-get request becomes the server ids allocated in the net-thread.
For get and multi-get requests in non-sharded mode this is only one server id. For multi-get requests in sharded mode this is a set of server ids. (if the number of keys is larger than the number of server then this will be all servers).

Since the net-thread is a singleton and the request queue offers first come first served processing of requests, the order in which they are processed does not change and hence when neglecting network related effects it can be expected that the work will be distributed evenly among the available servers.

Another form of work balancing takes place with the different number of worker threads. For a single worker-thread there is no balancing. \todo{continue this argument}

The balancing of the read workload comes at the cost of the write-workload. Since the value in each set request is replicated in all memcached servers, the server service time is determined by the slowest server. 


\subsubsection{Logging Infrastructure}

log4j2 asynchronous loggers

\todo{cite: https://logging.apache.org/log4j/2.x/manual/async.html}

\subsection{Experimental Setup}

\subsubsection{Metrics}\label{measured-points}



\begin{tabular}{|c|l|l|}
	\hline 
	\textbf{Origin} & \textbf{Metric} & \textbf{Description} \Tstrut \\ 
	\hline 
	\multirow{2}{*}{client} & - throughput & as measured by memtier \Tstrut \\ 
	& - response time & as measured by memtier \\ 
	\hline 
	\multirow{8}{*}{mw} & - throughput & per 5 second window \Tstrut \\ 
	& - response time & time between request arrived in mw and left mw\\ 
	& - net-thread processing time & time between request arrived and was enqueued\\  
	& - queue waiting time & time request was in the queue \\ 
	& - worker-thread processing time &  \\ 
	& - server service time & time memcached needed to process the request\\  
	& - queue length & sampled every 5 seconds \\  
	& - request arrival rate & per 5 second window \\ 
	\hline 
\end{tabular} 
\todo{write explanation of worker-thread processing time}

In every graph of the report the origin of the data (i.e. middleware or client) is presented usually in the bottom right corner.


\begin{figure}
	\centering
	\includegraphics[width=0.8\linewidth]{data/response-time-decomposition.png}
	\caption{components of client response time}
\end{figure}
\todo{do properly with pdf and color scheme}

\subsubsection{Statistic}

Each worker-thread has a separate statistic unit \emph{(Statistic.java)} which is updated after the processing of each request with the method \emph{update(request)}.  
The statistic unit is collecting online averages and sample standard deviations of the metrics over a five second window using \emph{Welford's Algorithm}.\cite{Knuth:1997:ACP:270146}

\todo{mention record count, M2 and avg => can calculate sample variance}


\begin{equation}
	\bar{x}_n = \bar{x}_{n-1} + \frac{x_n -\bar{x}_{n-1}}{n}
\end{equation}

\begin{equation}
	M_{2,n} = M_{2,n-1} + (x_n - \bar{x}_{n-1})(x_n - \bar{x}_n)
\end{equation}

\begin{equation}
	s^2_n = \frac{M_{2,n}}{n-1}
\end{equation}

Essentially this allows to get an insight into the respective metric without affecting the system performance too much through extensive logging of the performance of every single request to a file. 

Every five seconds the metrics are logged to a file and then reset afterwards.

This allows to calculate offline three different error every metrics for each 

- standard deviation within the 5 second window
- standard deviation of 5 second averages over the run of the middleware
- standard deviation over experiment repetitions 

\todo{write about rt hist and how its collected}


\subsubsection{Base Configuration}
- memcached (version) 1 thread
- 4096B values
- memtier benchmark (version) with configuration
\subsubsection{Simulation}\label{simulation}

The simulation results were obtained using up to 8 virtual machines on the \emph{Microsoft Azure} cloud:
\begin{itemize}
	\item 3 Client VMs of type Basic A2 (2 vcpus, 3.5 GB memory) each running one or two instances of the \emph{memtier benchmark}
	\item 2 Middleware of type Basic A4 (8 vcpus, 14 GB memory) running the middleware software
	\item 3 Server VM of type Basic A1 (1 vcpus, 1.75 GB memory) each running an instance of the \emph{memcached} key value store
\end{itemize}

All experiments were orchestrated with the \emph{python} script outlined in algorithm \ref{exp-suite-algo} running on a local machine that uses temporary \emph{ssh} connections to start, initialize and stop the run of an experiment. After each run  the resulting log files were transferred to the local machine and stored in a \emph{MongoDB}.
 
Before every experiment the network topology of all involved VMs was analysed by running a bandwidth test using \emph{iperf}. This in combination with the 4096B value size results in an estimate for the maximal achievable throughput for the given VM configuration and helps to identify when the network bandwidth is the bottleneck of the system.

The obtained results are filtered (10 seconds warmup and cooldown phase) and aggregated off-line using \emph{MongoDB} queries before being visualized using matlibplot.

\begin{algorithm}
	\ForEach
	{
		set of experiments
	}{
		- measure bandwidth and ping of the current network topology using \emph{iperf} and \emph{ping}
		
		\ForEach{experiment}{
			\ForEach
			{
				repetition
			}{
				- start all memcached instances with one thread
				
				- initialize all memcached instances by populating the key value store to avoid cache misses
				
				- start all middlewares according to the config
				
				- start all client benchmarks for 80 seconds with a value size of 4096B according to the config
				
				- wait 80 seconds
				
				- stop all middlewares
				
				- stop all memcached instances
				
				- transfer results using \emph{SCP}
				
				- store results in local \emph{MongoDB}
			
				- validate results
			}
		}
	}
	\caption{Each section of the report represents a set of experiment where different configurations were evaluated using at least three repetitions each.}\label{exp-suite-algo}
\end{algorithm}


- baseline without middleware run separately all other experiments were run without shutting down the vm to allow comparison of results not only within an experiment but also between experiments.
- after 10 sec warm up and cooldown phase ensured stable 1 minute throughput performance by checking coefficient of variation. In case an external source on the cloud prevented a stable execution phase of one minute, the experiment was repeated.
- before every run, restart all memcached instances, initialize them by filling all keys, restart mw's



\todo{System Overview
(Mapping code to functionality / Explanation how queues and threads are implemented 15)
insert overview picture}

- Description of the data-structures for holding connections 6 

- Parsing Requests: 
(Description how requests are parsed 6)
\todo{insert processing schematic}

- Processing of Requests in Worker:
- Set Request
- Get Request
- MultiGet Request (Sharded vs Non Sharded)
Description how SET requests are processed 6 Description how GET requests are processed 6 Description how Multi-GET requests are processed 6 

- Description how work is balanced (if not round-robin: proof required) 15 
-> here get, multiget sharded, maybe also worker balances work

- Statistics (Explanations related to statistics 15)
-> Sampling of queue size, arrival rate in 5 sec windows
-> Welfords Algorithm Online Averages with Std Deviation within 5 sec windows, reported 5sec aggregations (allows insight std dev gives insight in window without slowing down system too much through logging)
\todo{cite welford algorithm}

\end{document}